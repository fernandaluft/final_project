{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "# Check if the code is running on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    base_path = \"/content/\"\n",
        "    if Path(f\"{base_path}final_project\").is_dir():\n",
        "      %cd {base_path}final_project\n",
        "      !git pull\n",
        "      %cd {base_path}\n",
        "    else:\n",
        "      !git clone https://github.com/fernandaluft/final_project.git\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    base_path = \"/workspaces/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otW-aVRTE_F2",
        "outputId": "cd23d132-1305-49ca-8689-a26f1c24f3f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'final_project'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 195 (delta 9), reused 15 (delta 6), pack-reused 173\u001b[K\n",
            "Receiving objects: 100% (195/195), 139.78 MiB | 37.80 MiB/s, done.\n",
            "Resolving deltas: 100% (96/96), done.\n",
            "Updating files: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from final_project.src.scraping import Scraping\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pickle\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "5_qVf-u0E0JD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3d4d12-ceec-4a76-aa26-e2895ea8f6a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scraping = Scraping(IN_COLAB, sentiment_ds = True)\n",
        "scraping.kaggle_scrape()"
      ],
      "metadata": {
        "id": "GkMOiRBOExvh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RWpBeEQgBv4n"
      },
      "outputs": [],
      "source": [
        "class SentimentMLTrain():\n",
        "  def __init__(self, dataset_limit):\n",
        "    self.dataset_limit = dataset_limit\n",
        "    self.stop_words = set(stopwords.words('english'))\n",
        "    self.lemmatizer = WordNetLemmatizer()\n",
        "    self.tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
        "    self.best_model = None\n",
        "\n",
        "  def read_sentiment_dataset(self):\n",
        "    !unzip -o -n /content/imdb-dataset-of-65k-movie-reviews-and-translation.zip -d {base_path}final_project/data\n",
        "    os.system(f'rm -rf /content/imdb-dataset-of-65k-movie-reviews-and-translation.zip')\n",
        "    self.sentiment_df = pd.read_csv(f\"{base_path}final_project/data/IMDB-Dataset.csv\").sample(5000)\n",
        "\n",
        "  def preprocess_text(self, text):\n",
        "    text = re.sub(r'\\W|\\d', ' ', str(text))  # Remove special characters and digits\n",
        "    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
        "    lemmatized_tokens = [self.lemmatizer.lemmatize(word) for word in tokens if word not in self.stop_words]  # Lemmatize and remove stopwords\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "  def preprocess_data(self):\n",
        "    self.sentiment_df['clean_text'] = self.sentiment_df['Reviews'].apply(self.preprocess_text)\n",
        "\n",
        "  def split_data(self):\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "        self.tfidf_vectorizer.fit_transform(self.sentiment_df['clean_text']),\n",
        "        self.sentiment_df['Ratings'],\n",
        "        test_size=0.2,\n",
        "        random_state=42)\n",
        "    with open('/content/final_project/models/tf_idf.pickle', 'wb') as f:\n",
        "      pickle.dump(self.tfidf_vectorizer, f)\n",
        "\n",
        "  def train_model(self):\n",
        "    svm_classifier = SVC(kernel='linear')\n",
        "    param_grid = {'C': [0.1, 1, 10, 100]}  # Hyperparameter grid for tuning\n",
        "    grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
        "    grid_search.fit(self.X_train, self.y_train)\n",
        "    self.best_model = grid_search.best_estimator_\n",
        "\n",
        "  def evaluate_model(self):\n",
        "    y_pred = self.best_model.predict(self.X_test)\n",
        "    accuracy = accuracy_score(self.y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(classification_report(self.y_test, y_pred))\n",
        "\n",
        "  def save_model(self, model_path):\n",
        "    with open(model_path, 'wb') as f:\n",
        "      pickle.dump(self.best_model, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_ml_train = SentimentMLTrain(None)\n",
        "sentiment_ml_train.read_sentiment_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLxku95UIdAZ",
        "outputId": "8e5b35ae-f39b-4111-954a-fb459c18671d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caution:  both -n and -o specified; ignoring -o\n",
            "Archive:  /content/imdb-dataset-of-65k-movie-reviews-and-translation.zip\n",
            "  inflating: /content/final_project/data/IMDB-Dataset.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_ml_train.sentiment_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX8xvMc54H-K",
        "outputId": "f937c676-0029-453e-e48f-cfa09612ce3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1000 entries, 144037 to 130582\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Ratings   1000 non-null   float64\n",
            " 1   Reviews   1000 non-null   object \n",
            " 2   Movies    999 non-null    object \n",
            " 3   Resenhas  1000 non-null   object \n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 39.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_ml_train.preprocess_data()\n",
        "sentiment_ml_train.split_data()\n",
        "sentiment_ml_train.train_model()\n",
        "sentiment_ml_train.evaluate_model()"
      ],
      "metadata": {
        "id": "oYADLwbhJgLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6263ea46-596f-445a-cc8d-7d7630f1a35d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.265\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.52      0.52      0.52        25\n",
            "         2.0       0.19      0.28      0.23        18\n",
            "         3.0       0.29      0.32      0.30        19\n",
            "         4.0       0.24      0.25      0.24        20\n",
            "         5.0       0.12      0.27      0.17        15\n",
            "         6.0       0.21      0.22      0.22        18\n",
            "         7.0       0.13      0.09      0.11        22\n",
            "         8.0       0.20      0.08      0.12        24\n",
            "         9.0       0.39      0.44      0.41        16\n",
            "        10.0       0.38      0.22      0.28        23\n",
            "\n",
            "    accuracy                           0.27       200\n",
            "   macro avg       0.27      0.27      0.26       200\n",
            "weighted avg       0.28      0.27      0.26       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_ml_train.save_model(\"/content/final_project/models/sentiment_model.pkl\")"
      ],
      "metadata": {
        "id": "MKqrbdSF4kfr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o -n /content/final_project/preprocessed_data/xaa_books_reviews.zip -d {base_path}final_project/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvIEQAdR50f3",
        "outputId": "7a3a8354-25df-483a-f319-76fefd7890c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caution:  both -n and -o specified; ignoring -o\n",
            "Archive:  /content/final_project/preprocessed_data/xaa_books_reviews.zip\n",
            "  inflating: /content/final_project/data/content/final_project/data/books_reviews.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def calculate_sentiment_book(title):\n",
        "  sentiment_ml = SentimentMLTrain(None)\n",
        "  n_neg = 0\n",
        "  n_pos = 0\n",
        "  with open(\"/content/final_project/models/sentiment_model.pkl\", \"rb\") as f:\n",
        "    sentiment_model = pickle.load(f)\n",
        "\n",
        "  with open(\"/content/final_project/models/tf_idf.pickle\", \"rb\") as f:\n",
        "    vec = pickle.load(f)\n",
        "  books = pd.read_csv(\"/content/final_project/data/content/final_project/data/books_reviews.csv\")\n",
        "\n",
        "\n",
        "  books_subset = books[books.Title == title]['review/text']\n",
        "\n",
        "  for rev, rev2 in books_subset.items():\n",
        "\n",
        "    processed = sentiment_ml.preprocess_text(rev2)\n",
        "    processed = vec.transform([processed])\n",
        "\n",
        "    score = sentiment_model.predict(processed)\n",
        "    if score >= 5:\n",
        "      n_pos += 1\n",
        "    else:\n",
        "      n_neg += 1\n",
        "\n",
        "  return [n_neg, n_pos]"
      ],
      "metadata": {
        "id": "JylC5moh6jD8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_sentiment_book('Run Baby Run'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hmZCeDP-Coa",
        "outputId": "cd9512df-05fa-4c46-d5f7-95b082ff5b22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 4943)\t0.14723072167214837\n",
            "  (0, 4934)\t0.12095300774538859\n",
            "  (0, 4907)\t0.12156474474597473\n",
            "  (0, 4521)\t0.12512474271979876\n",
            "  (0, 4497)\t0.05331095556624568\n",
            "  (0, 4393)\t0.13826479363361338\n",
            "  (0, 4207)\t0.11099748855323574\n",
            "  (0, 4205)\t0.1451889238594452\n",
            "  (0, 3559)\t0.3099455944161144\n",
            "  (0, 3236)\t0.13151126248020392\n",
            "  (0, 3189)\t0.10749064973343528\n",
            "  (0, 3074)\t0.27652958726722676\n",
            "  (0, 3064)\t0.08116472120279151\n",
            "  (0, 3033)\t0.19880198289466547\n",
            "  (0, 2769)\t0.15183333937650076\n",
            "  (0, 2430)\t0.04774393122814306\n",
            "  (0, 2424)\t0.08059269382847838\n",
            "  (0, 2207)\t0.13983960294176587\n",
            "  (0, 2164)\t0.16853338826413944\n",
            "  (0, 2117)\t0.1451889238594452\n",
            "  (0, 2013)\t0.11182137382825734\n",
            "  (0, 1963)\t0.1155842568290911\n",
            "  (0, 1585)\t0.1281333647209562\n",
            "  (0, 1572)\t0.06427267389239831\n",
            "  (0, 1185)\t0.17355665020279212\n",
            "  (0, 1179)\t0.12241255508989692\n",
            "  (0, 932)\t0.1432880555722661\n",
            "  (0, 783)\t0.1155842568290911\n",
            "  (0, 722)\t0.1606072689922812\n",
            "  (0, 700)\t0.2988720626258946\n",
            "  (0, 618)\t0.16428628081063737\n",
            "  (0, 499)\t0.16428628081063737\n",
            "  (0, 482)\t0.1451889238594452\n",
            "  (0, 467)\t0.4222256228629806\n",
            "  (0, 425)\t0.15736215058480552\n",
            "  (0, 182)\t0.08097272278003698\n",
            "  (0, 133)\t0.06599521364654398\n",
            "  (0, 4965)\t0.1497234521055526\n",
            "  (0, 4897)\t0.15937545582664173\n",
            "  (0, 4809)\t0.08485837396496294\n",
            "  (0, 4592)\t0.21179904162186455\n",
            "  (0, 4591)\t0.13735667812943397\n",
            "  (0, 4207)\t0.14939527459838362\n",
            "  (0, 3823)\t0.19434959603203694\n",
            "  (0, 3566)\t0.18037893729744275\n",
            "  (0, 3565)\t0.11249254388731032\n",
            "  (0, 3563)\t0.1754272308397745\n",
            "  (0, 3559)\t0.27811084011536885\n",
            "  (0, 3275)\t0.13905542005768443\n",
            "  (0, 3113)\t0.16593652669493303\n",
            "  (0, 2798)\t0.19541468398379647\n",
            "  (0, 2770)\t0.17105951620128895\n",
            "  (0, 2626)\t0.119996916700499\n",
            "  (0, 2601)\t0.2268347883082183\n",
            "  (0, 2591)\t0.07690747400307535\n",
            "  (0, 2430)\t0.06426017209221664\n",
            "  (0, 2424)\t0.10847243286368928\n",
            "  (0, 1989)\t0.19285624105468202\n",
            "  (0, 1933)\t0.16039148415342078\n",
            "  (0, 1858)\t0.18409030357844844\n",
            "  (0, 1701)\t0.21179904162186455\n",
            "  (0, 1359)\t0.22111846271801835\n",
            "  (0, 1316)\t0.1268272732116519\n",
            "  (0, 1314)\t0.1440071265153527\n",
            "  (0, 1294)\t0.2268347883082183\n",
            "  (0, 1293)\t0.08031194710534943\n",
            "  (0, 1045)\t0.17105951620128895\n",
            "  (0, 406)\t0.09194322068942908\n",
            "  (0, 346)\t0.22111846271801835\n",
            "  (0, 345)\t0.22111846271801835\n",
            "  (0, 344)\t0.14895883297302095\n",
            "  (0, 205)\t0.15130167811976042\n",
            "  (0, 4951)\t0.2800349712117451\n",
            "  (0, 4934)\t0.10308551595064401\n",
            "  (0, 4694)\t0.3614589821482631\n",
            "  (0, 4604)\t0.2737638938974528\n",
            "  (0, 4437)\t0.11833267743525638\n",
            "  (0, 4291)\t0.23836426870723648\n",
            "  (0, 3575)\t0.19872445271724717\n",
            "  (0, 3515)\t0.23567991991623316\n",
            "  (0, 3342)\t0.21492998767131502\n",
            "  (0, 3270)\t0.11422846746373946\n",
            "  (0, 3218)\t0.25096283573713324\n",
            "  (0, 3199)\t0.2682324116864482\n",
            "  (0, 2676)\t0.2058117769370215\n",
            "  (0, 2669)\t0.2682324116864482\n",
            "  (0, 2180)\t0.23567991991623316\n",
            "  (0, 1863)\t0.11287273113822878\n",
            "  (0, 1783)\t0.21328198284434657\n",
            "  (0, 1392)\t0.21328198284434657\n",
            "  (0, 562)\t0.17610641858680773\n",
            "  (0, 310)\t0.20184068139614256\n",
            "  (0, 4905)\t0.19406004149182077\n",
            "  (0, 4464)\t0.37883303059246737\n",
            "  (0, 4461)\t0.1981292892146742\n",
            "  (0, 4130)\t0.3560961524311706\n",
            "  (0, 3585)\t0.31691531952021107\n",
            "  (0, 3575)\t0.14296974308300614\n",
            "  (0, 3559)\t0.253394980601087\n",
            "  (0, 3479)\t0.37883303059246737\n",
            "  (0, 3190)\t0.31426500701502447\n",
            "  (0, 1797)\t0.12160045146433342\n",
            "  (0, 1701)\t0.3859526944065735\n",
            "  (0, 1376)\t0.24831181005266406\n",
            "[0, 4]\n"
          ]
        }
      ]
    }
  ]
}